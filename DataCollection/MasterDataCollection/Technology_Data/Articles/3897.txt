AdvertisementSupported byBitsBy Quentin HardyIs Facebook two-faced?The social network claims it is in the business of connecting people and things, largely through powerful (and supposedly impartial) algorithms that focus on things like what other people are reading and talking about online, as well as a user’s own interests.Now, however, Facebook is facing accusations of all too human censorship after a report on the website Gizmodo said curators working for Facebook suppressed news stories from typically conservative outlets because they didn’t like the politics, write John Herrman and Mike Isaac.Gizmodo’s story said a team of people assigned to post links and brief story descriptions to the Facebook “Trending” section suppressed stories about Paul Ryan, Mitt Romney and conservative gatherings, even though Facebook’s computers flagged these as popular items. The site also said certain stories were inserted arbitrarily, and stories about Facebook itself were left off. These decisions appear to have been at the whim of managers and differed depending on who was in charge.It’s not clear that there really is liberal bias inside Facebook. Mr. Herrman and Mr. Isaac report talking with other former employees on the “trending” desk who said left-wing stories were also bounced, despite qualifying for a ranking. And the prime source in the Gizmodo story is a self-described conservative. So maybe this is a story about conservative bias against liberal bias against conservative biased media. As the kids say, ugh.More important may be the fact that, in Facebook’s algorithm-driven world, the scandal is happening in a corner where humans were in charge.The Facebook employees also seem to have believed they were being observed, Gizmodo said in a different story, so that they might someday be replaced by software to write the trending briefs. That wouldn’t be too surprising: There is already software that writes sports and breaking disaster stories, and Facebook is good at revising algorithms and building products on a big scale.That means the outcome of this scandal, regardless of whether bias is confirmed, may well be more robo journalism, as Facebook strives to look impartial by letting computers do the work.Advertisement